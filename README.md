# Algoritmos de Ordena√ß√£o

## üìÑ Descri√ß√£o
Implementa√ß√£o de diversos algoritmos de ordena√ß√£o em linguagem C:  
**Bubble Sort**, **Selection Sort**, **Insertion Sort**, **Quick Sort**, **Merge Sort**, **Heap Sort**,**Counting Sort**, **Bucket Sort** e **Radix Sort**.  

O programa compara o desempenho desses algoritmos medindo o tempo de execu√ß√£o e armazena os n√∫meros ordenados em arquivos de sa√≠da.

Os n√∫meros a serem ordenados s√£o lidos de arquivos de entrada, e os resultados s√£o salvos em arquivos de sa√≠da separados para cada algoritmo.

---

## üóÇÔ∏è Estrutura dos Arquivos

- **src**: Cont√©m os arquivos de implementa√ß√£o;
- **include**: Cont√©m os arquivos de cabe√ßalho;
- **instancias**: Cont√©m os arquivos de entrada com os n√∫meros a serem ordenados;
- **resultados.csv**: Cont√©m o arquivo com os resultados de an√°lise de cada algoritmo;
- **grafico_TIPODOVETOR**: Cont√©m o gr√°fico comparando os algoritmos para cada tipo de entrada;
- **gerar_grafico.py**: Arquivo que gera os gr√°ficos a partir do arquivo csv;
- **Makefile:** Arquivo de configura√ß√£o para a compila√ß√£o.

---

## ‚öôÔ∏è Como Compilar e Executar

### Compilando o C√≥digo

```bash
make
```

### Executando o Programa

```bash
./bin/programa
```

O programa ir√°:
- Ler os n√∫meros do arquivo de entrada;
- Ordenar os n√∫meros usando os algoritmos;
- Medir o tempo de execu√ß√£o de cada algoritmo;
- Salvar os resultados em arquivos de sa√≠da.

---

## üñ•Ô∏è Sa√≠da do Programa
Os resultados estar√£o no arquivo csv.

### Gerar os gr√°ficos de compara√ß√£o dos algoritmos

```bash
python gerar_grafico.py
```

---

## üìö Detalhes dos Algoritmos

### Bubble Sort
- **Descri√ß√£o:** Compara pares de elementos adjacentes e troca-os se estiverem na ordem errada. Repete o processo at√© que o vetor esteja ordenado.
- **Complexidade de tempo:** O(n¬≤) no pior caso.
- **Vantagens:** Simples de implementar.
- **Desvantagens:** Muito lento para vetores grandes.

---

### Selection Sort
- **Descri√ß√£o:** Procura o menor elemento do vetor e troca de posi√ß√£o com o elemento da posi√ß√£o atual. Repete at√© o vetor estar ordenado.
- **Complexidade de tempo:** O(n¬≤) no pior caso.
- **Vantagens:** Simples e com n√∫mero m√≠nimo de trocas.
- **Desvantagens:** Ineficiente para grandes volumes de dados.

---

### Insertion Sort
- **Descri√ß√£o:** Insere cada elemento na posi√ß√£o correta, considerando as partes j√° ordenadas do vetor.
- **Complexidade de tempo:** O(n¬≤) no pior caso, mas O(n) no melhor caso (vetor j√° ordenado).
- **Vantagens:** Bom para vetores pequenos ou quase ordenados.
- **Desvantagens:** Ineficiente para vetores grandes.

---

### Quick Sort
- **Descri√ß√£o:** Algoritmo de divis√£o e conquista. Escolhe um piv√¥ e particiona o vetor em sub-vetores menores, ordenando-os recursivamente.
- **Complexidade de tempo:** O(n log n) no caso m√©dio, O(n¬≤) no pior caso.
- **Vantagens:** Geralmente r√°pido, com bom desempenho pr√°tico.
- **Desvantagens:** Pior caso pode ser ruim sem escolha adequada do piv√¥.

---

### Merge Sort
- **Descri√ß√£o:** Divide o vetor em sub-vetores menores, ordena cada um e faz a fus√£o ordenada.
- **Complexidade de tempo:** O(n log n) no pior caso.
- **Vantagens:** Est√°vel (mant√©m ordem relativa) e previs√≠vel.
- **Desvantagens:** Usa mem√≥ria extra proporcional ao tamanho do vetor.

---

### Heap Sort
- **Descri√ß√£o:** Constr√≥i uma heap a partir do vetor e extrai o maior elemento sucessivamente, reconstruindo a heap.
- **Complexidade de tempo:** O(n log n) no pior caso.
- **Vantagens:** Desempenho consistente, sem pior caso degenerado.
- **Desvantagens:** Mais lento que Quick Sort na pr√°tica para muitos casos.

---

### Counting Sort

- **Descri√ß√£o:** Conta a frequ√™ncia de cada valor e usa essa contagem para reconstruir o vetor em ordem.

- **Complexidade de tempo:** O(n + k), onde k √© o valor m√°ximo no vetor.

- **Vantagens:** Extremamente eficiente para intervalos pequenos de valores inteiros.

- **Desvantagens:** Requer mem√≥ria proporcional ao valor m√°ximo, n√£o √© comparativo.

---

### Bucket Sort

- **Descri√ß√£o:** Distribui os elementos em "baldes" (intervalos), ordena individualmente cada balde (geralmente com Insertion Sort) e os combina.

- **Complexidade de tempo:** O(n + k), no caso m√©dio, dependendo da distribui√ß√£o dos dados.

- **Vantagens:** Muito eficiente para dados uniformemente distribu√≠dos.

- **Desvantagens:** Desempenho pode degradar se os dados n√£o forem bem distribu√≠dos.

---

### Radix Sort

- **Descri√ß√£o:** Ordena n√∫meros processando d√≠gito por d√≠gito, geralmente da menor posi√ß√£o para a maior, utilizando Counting Sort como sub-rotina est√°vel.

- **Complexidade de tempo:** O(d √ó (n + k)), onde d √© o n√∫mero de d√≠gitos.

- **Vantagens:** Muito eficiente para n√∫meros inteiros de tamanho fixo.

- **Desvantagens:** Requer que o algoritmo auxiliar (como Counting Sort) seja est√°vel.

## Algoritmos Avaliados

- Selection Sort
- Insertion Sort
- Quick Sort
- Merge Sort

---

# üîµ 1. Inst√¢ncias Aleat√≥rias

## Comportamento Observado

- **Selection Sort:** Crescimento quadr√°tico evidente.
- **Insertion Sort:** Tamb√©m apresenta crescimento Œò(n¬≤).
- **Quick Sort:** Crescimento aproximadamente Œò(n log n).
- **Merge Sort:** Crescimento est√°vel Œò(n log n).

## An√°lise Te√≥rica

| Algoritmo       | Melhor Caso | Caso M√©dio | Pior Caso |
|---------------|------------|------------|------------|
| Selection     | Œò(n¬≤)     | Œò(n¬≤)     | Œò(n¬≤)     |
| Insertion     | Œò(n)      | Œò(n¬≤)     | Œò(n¬≤)     |
| Quick         | Œò(n log n)| Œò(n log n)| Œò(n¬≤)     |
| Merge         | Œò(n log n)| Œò(n log n)| Œò(n log n)|

## Conclus√£o

Para dados aleat√≥rios, algoritmos Œò(n log n) escalam muito melhor.  
A diferen√ßa entre crescimento quadr√°tico e n log n torna-se extremamente significativa para grandes entradas.

---

# üü¢ 2. Inst√¢ncias com Alta Repeti√ß√£o de Valores

## Comportamento Observado

- **Selection Sort:** Sem altera√ß√µes significativas.
- **Insertion Sort:** Pequena melhora dependendo da organiza√ß√£o.
- **Quick Sort:** Pode apresentar melhor balanceamento nas parti√ß√µes.
- **Merge Sort:** Mant√©m comportamento est√°vel.

## An√°lise

A repeti√ß√£o de valores pode favorecer o Quick Sort, pois o particionamento tende a gerar divis√µes mais equilibradas.  
O Merge Sort permanece constante, pois sua complexidade n√£o depende da distribui√ß√£o dos dados.

## Conclus√£o

Algoritmos baseados em divis√£o e conquista mant√™m estabilidade, enquanto algoritmos quadr√°ticos continuam pouco escal√°veis.

---

# üü° 3. Inst√¢ncias J√° Ordenadas

## Comportamento Observado

- **Selection Sort:** Continua Œò(n¬≤).
- **Insertion Sort:** Aproxima-se de Œò(n) (melhor caso).
- **Quick Sort:** Pode piorar dependendo da escolha do piv√¥.
- **Merge Sort:** Mant√©m Œò(n log n).

## An√°lise

O Insertion Sort √© altamente eficiente quando os dados j√° est√£o ordenados, pois realiza poucas trocas.  
O Selection Sort n√£o se beneficia da ordena√ß√£o pr√©via, pois sempre realiza o mesmo n√∫mero de compara√ß√µes.

## Conclus√£o

Para dados quase ordenados, Insertion Sort pode ser uma escolha eficiente.  
Merge Sort mant√©m desempenho previs√≠vel.

---

# üî¥ 4. Inst√¢ncias Inversamente Ordenadas

## Comportamento Observado

- **Selection Sort:** Mant√©m Œò(n¬≤).
- **Insertion Sort:** Apresenta pior caso Œò(n¬≤).
- **Quick Sort:** Pode se aproximar de Œò(n¬≤) se o piv√¥ for mal escolhido.
- **Merge Sort:** Mant√©m Œò(n log n).

## An√°lise

O Insertion Sort sofre forte degrada√ß√£o neste cen√°rio, pois cada elemento precisa ser deslocado diversas posi√ß√µes.  
Merge Sort mant√©m estabilidade, independentemente da ordem inicial.

## Conclus√£o

Algoritmos quadr√°ticos s√£o altamente sens√≠veis √† organiza√ß√£o inicial dos dados.  
Merge Sort demonstrou maior robustez geral.

---

# üèÅ Conclus√£o Geral

- Algoritmos Œò(n¬≤) s√£o adequados apenas para entradas pequenas.
- Algoritmos Œò(n log n) apresentam melhor escalabilidade.
- Merge Sort √© o mais est√°vel em todos os cen√°rios.
- Quick Sort apresenta excelente desempenho m√©dio, mas depende da escolha do piv√¥.
- A an√°lise experimental confirmou a teoria da complexidade assint√≥tica.

---

# üìå Considera√ß√µes Finais

Os experimentos demonstraram na pr√°tica o impacto da complexidade assint√≥tica no desempenho real dos algoritmos.  
A escolha do algoritmo adequado deve considerar:

- Tamanho da entrada
- Distribui√ß√£o dos dados
- Sensibilidade a pior caso
- Requisitos de estabilidade